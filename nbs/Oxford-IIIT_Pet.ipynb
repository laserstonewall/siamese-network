{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from collections import defaultdict\n",
    "\n",
    "from siamese.dataprep import SiamesePairedDataset\n",
    "from siamese.networks import SiameseNetwork\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oxford-IIIT Pets Dataset\n",
    "The pets dataset was assembled in 2012 by researchers at the University of Oxford in the UK and the International Institute of Information Technology in Hyderabad, India. It consists of 7,349 images of 25 cat and 12 dog breeds (37 total breeds), with about 200 images from each breed. There are associated annotations for the images, including labels as well as bounding boxes for object localization studies.\n",
    "\n",
    "The data set can be found here: [Oxford-IIIT Pets Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/)\n",
    "\n",
    "To easily pull it locally, run the following, which will create a directory `data` in the `nbs` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "--2021-07-13 12:58:29--  https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
      "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
      "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 791918971 (755M) [application/x-gzip]\n",
      "Saving to: ‘data/images.tar.gz.1’\n",
      "\n",
      "images.tar.gz.1     100%[===================>] 755.23M  16.1MB/s    in 47s     \n",
      "\n",
      "2021-07-13 12:59:17 (15.9 MB/s) - ‘data/images.tar.gz.1’ saved [791918971/791918971]\n",
      "\n",
      "--2021-07-13 12:59:17--  https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
      "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
      "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19173078 (18M) [application/x-gzip]\n",
      "Saving to: ‘data/annotations.tar.gz.1’\n",
      "\n",
      "annotations.tar.gz. 100%[===================>]  18.28M  11.2MB/s    in 1.6s    \n",
      "\n",
      "2021-07-13 12:59:19 (11.2 MB/s) - ‘data/annotations.tar.gz.1’ saved [19173078/19173078]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!wget -P data https://www.robots.ox.ac.uk/\\~vgg/data/pets/data/images.tar.gz\n",
    "!wget -P data https://www.robots.ox.ac.uk/\\~vgg/data/pets/data/annotations.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf data/images.tar.gz -C data\n",
    "!tar -xf data/annotations.tar.gz -C data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the `tar.gz` files, you should see two folders: `images` and `annotations`. `images` contains all the image files in `.jpg` format. \n",
    "\n",
    "`annotations` contains several files:\n",
    "\n",
    "- `list.txt`: Each row identifies the image name, class id (breed), whether the image is a cat or dog, and the breed id within the cats/dogs class.\n",
    "- `trainval.txt` and `test.txt`: Pre-determined 50% splits of the training data into a dataset for training+validation runs, and then a 50% holdout set for testing.\n",
    "- `xmls`: Location annotation for tight bounding box around the pet head, for object localization work.\n",
    "- `trimaps`: Pixel level foreground/background masks for object segmentation work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load / prepare file and class definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base directory location where the image and annotation folders live\n",
    "BASE_DATA_PATH = './data'\n",
    "\n",
    "# Load in the space-delimited CSV file, skipping leading comment rows and adding column names\n",
    "data = pd.read_csv(f'{BASE_DATA_PATH}/annotations/list.txt', \n",
    "                   header=None, \n",
    "                   skiprows=6, \n",
    "                   delimiter=' ',\n",
    "                   names=['image', 'label', 'species', 'breed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7349, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>species</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abyssinian_100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abyssinian_101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abyssinian_102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abyssinian_103</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abyssinian_104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image  label  species  breed\n",
       "0  Abyssinian_100      1        1      1\n",
       "1  Abyssinian_101      1        1      1\n",
       "2  Abyssinian_102      1        1      1\n",
       "3  Abyssinian_103      1        1      1\n",
       "4  Abyssinian_104      1        1      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using our custom SiameseDataset class in order to load paired image samples for our Siamese neural network. In order to load in the images, it needs a pandas DataFrame with two columsn: 1) the full path for all images, 2) the class label for each image.\n",
    "\n",
    "The `image` column in  `data` needs the full path and image extension (`.jpg` for all our images) added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['image'] = data['image'].map(lambda image_name: os.path.join(BASE_DATA_PATH, 'images', f'{image_name}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>species</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/images/Abyssinian_100.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/images/Abyssinian_101.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/images/Abyssinian_102.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/images/Abyssinian_103.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/images/Abyssinian_104.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  image  label  species  breed\n",
       "0  ../../data/images/Abyssinian_100.jpg      1        1      1\n",
       "1  ../../data/images/Abyssinian_101.jpg      1        1      1\n",
       "2  ../../data/images/Abyssinian_102.jpg      1        1      1\n",
       "3  ../../data/images/Abyssinian_103.jpg      1        1      1\n",
       "4  ../../data/images/Abyssinian_104.jpg      1        1      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train/validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the scikit learn `train_test_split` function to divide our data into a training and validation set, using the class label column for stratification to ensure we get the proper proportional representation of each class in the respective datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(data, stratify=data['label'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is fairly small, so as usual we'll want to apply some image augmentation techniques to reduce overfitting. `pytorch` transforms take care of this, as well as forcing the images into a standard size and format. We map the pixel values of the images to be in the range `[-1,1]`, which is the range used for the pre-trained ResNets we'll be using below.\n",
    "\n",
    "We separate the `train` and `validation` transforms, since we don't need to apply the random augmentation transformations for the `validation` set during inference. Here we do not use test-time augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (x - 0.5) / 0.5)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (x - 0.5) / 0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `pytorch` `Dataset` objects. Here we use the default uniform sampling, where each class is equally likely to be sampled, regardless of the relative class frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SiamesePairedDataset(train_df,\n",
    "                                     path_col='image',\n",
    "                                     label_col='label',\n",
    "                                     transform=transform_train)\n",
    "\n",
    "val_dataset = SiamesePairedDataset(val_df,\n",
    "                                   path_col='image',\n",
    "                                   label_col='label',\n",
    "                                   transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /home/chris/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5193170acd413dad067876acd8e2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User adjustable mini-batch size for mini-batch stochastic gradient descent\n",
    "batch_size = 64\n",
    "\n",
    "# Use the GPU as the main device\n",
    "device = torch.device(0)\n",
    "\n",
    "def get_model_learner():\n",
    "    # Appropriate splits for ResNet models, used to apply different learning rates\n",
    "    # to different layers through the fastai API\n",
    "    split_dict = {'resnet18': [26, 50],'resnet34': [41, 90], 'resnet50': [57, 124]}\n",
    "\n",
    "    # Initialize the Siamese neural network, using a pretrained ResNet as the\n",
    "    # the image feature extractor. A randomly initialized fully connected layer \n",
    "    # is added to determine the image similarity\n",
    "    model_ft = SiameseNetwork(models.resnet34(pretrained=True))\n",
    "\n",
    "    # Initialize the fastai vision DataBunch, which helps distribute\n",
    "    # the model data to the GPU for the learner\n",
    "    databunch = DataBunch.create(train_dataset, \n",
    "                                 val_dataset, \n",
    "                                 bs=batch_size, \n",
    "                                 device=device, \n",
    "                                 num_workers=8)\n",
    "\n",
    "    # Set the training criterion, usually CrossEntropy for the way we have\n",
    "    # the Siamese network set up with binary outputs indicating similar/dissimilar\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize the fastai learner, which helps coordinate model training, taking\n",
    "    # care of many of the low level details for us\n",
    "    learn = Learner(databunch, \n",
    "                    model_ft, \n",
    "                    loss_func=criterion, \n",
    "                    metrics=accuracy, \n",
    "                    layer_groups=split_model_idx(model_ft, split_dict['resnet34']))\n",
    "    \n",
    "    return learn\n",
    "\n",
    "learn = get_model_learner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the neural network\n",
    "\n",
    "For this first experiment we separated the dataset's images into the train and validation sets. For both datasets, all classes are represented, meaning each breed is in both the training and the validation sets.\n",
    "\n",
    "First we'll use the `fastai` learning rate finder, which begins training a single epoch for the network while stepping through increasing learning rates. This is used to determine an appropriate learning rate for the network and dataset, as described in Leslie Smith's 2015 work [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/pdf/1506.01186.pdf])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 00:22<00:22]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.904957</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      10.47% [9/86 00:03<00:26 2.4077]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/apps/miniconda3/envs/siamese/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot, we can see that a learning rate of `1e-3` is probably an appropriate place to train our network. We apply the one-cycle policy discussed in Leslie Smith's 2018 work [A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay](https://arxiv.org/abs/1803.09820)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.634686</td>\n",
       "      <td>0.546201</td>\n",
       "      <td>0.726877</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.387329</td>\n",
       "      <td>0.267140</td>\n",
       "      <td>0.909684</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.255543</td>\n",
       "      <td>0.193912</td>\n",
       "      <td>0.940152</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.210447</td>\n",
       "      <td>0.179709</td>\n",
       "      <td>0.929271</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.182956</td>\n",
       "      <td>0.195359</td>\n",
       "      <td>0.928183</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.152319</td>\n",
       "      <td>0.131363</td>\n",
       "      <td>0.955930</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.127392</td>\n",
       "      <td>0.149276</td>\n",
       "      <td>0.949401</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.121613</td>\n",
       "      <td>0.135203</td>\n",
       "      <td>0.950490</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.105883</td>\n",
       "      <td>0.133211</td>\n",
       "      <td>0.955386</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.102231</td>\n",
       "      <td>0.110639</td>\n",
       "      <td>0.960827</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "learn.fit_one_cycle(10, slice(1e-5,1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the neural network, holding out a set of classes\n",
    "\n",
    "One of the major applications of Siamese neural networks is for one-shot learning. Here, a network is trained to learn when images are similar/dissimilar. For example, we train the network with a dataset consisting of many types of balls (basketball, baseball, raquetball, etc.). After training, we want to take a single image of a new type of ball (say it's never seen a tennis ball before), and use that to identify other tennis balls in new image data. \n",
    "\n",
    "This type of one-shot learning is very interesting for applications like facial recognition. Think about Apple's FaceID. It takes a few shots of your face from various angles, and from then on it can determine if new face images taken during the authentication process are you or someone else attempting to access your phone. Apple likely uses some sort of Siamese network underneath the hood to accomplish this, using a trained network to infer whether or not the new image is the phone's owner.\n",
    "\n",
    "In the training above, we haven't _quite_ tested this idea. We mixed in all the image classes together in both the training and validation sets. We didn't hold out our tennis ball during training, so the network had already seen tennis balls, and should have an easier time identifying images similar to a reference tennis ball image. We don't know if it's really learned general features that make ball types similar, or if it's memorized very specific features of each class.\n",
    "\n",
    "Let's try the same training, except we'll create our training and validation datasets from completely different classes, and test how well the network is learning to identify similar cat/dog breeds that it hasn't seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the unique set of classes\n",
    "classes = data['label'].unique()\n",
    "\n",
    "# Randomly choose 2/3 of the breeds (25) for the train set, the rest are the validation set\n",
    "train_classes = np.random.choice(classes, size=25, replace=False)\n",
    "val_classes   = set(classes) - set(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seprate the train and validation parts of our data\n",
    "train_df = data[data['label'].map(lambda x: x in train_classes)]\n",
    "val_df   = data[data['label'].map(lambda x: x in val_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4974, 4), (2375, 4), (7349, 4))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape, data.shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can carry through with the rest of our training as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SiamesePairedDataset(train_df,\n",
    "                                     path_col='image',\n",
    "                                     label_col='label',\n",
    "                                     transform=transform_train)\n",
    "\n",
    "val_dataset = SiamesePairedDataset(val_df,\n",
    "                                   path_col='image',\n",
    "                                   label_col='label',\n",
    "                                   transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_model_learner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 00:20<00:20]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.820161</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='16' class='' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.78% [16/77 00:04<00:18 2.3471]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.554996</td>\n",
       "      <td>0.470043</td>\n",
       "      <td>0.781053</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.297957</td>\n",
       "      <td>0.380450</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.189026</td>\n",
       "      <td>0.446970</td>\n",
       "      <td>0.825684</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.149350</td>\n",
       "      <td>0.386634</td>\n",
       "      <td>0.845895</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.115168</td>\n",
       "      <td>0.404818</td>\n",
       "      <td>0.845053</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = get_model_learner()\n",
    "learn.fit_one_cycle(5, slice(1e-5,1e-3))#slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.669222</td>\n",
       "      <td>0.603134</td>\n",
       "      <td>0.659790</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.432716</td>\n",
       "      <td>0.405177</td>\n",
       "      <td>0.839158</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.255557</td>\n",
       "      <td>0.388805</td>\n",
       "      <td>0.836632</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.181542</td>\n",
       "      <td>0.378362</td>\n",
       "      <td>0.850105</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.142584</td>\n",
       "      <td>0.432630</td>\n",
       "      <td>0.837474</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.126347</td>\n",
       "      <td>0.438615</td>\n",
       "      <td>0.829895</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.104178</td>\n",
       "      <td>0.409597</td>\n",
       "      <td>0.848421</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.079840</td>\n",
       "      <td>0.376394</td>\n",
       "      <td>0.851368</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075346</td>\n",
       "      <td>0.373448</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076464</td>\n",
       "      <td>0.398080</td>\n",
       "      <td>0.851368</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = get_model_learner()\n",
    "learn.fit_one_cycle(10, slice(1e-5,1e-3))#slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.668642</td>\n",
       "      <td>0.626179</td>\n",
       "      <td>0.612211</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.474935</td>\n",
       "      <td>0.427883</td>\n",
       "      <td>0.829474</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.289705</td>\n",
       "      <td>0.351642</td>\n",
       "      <td>0.854316</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.200034</td>\n",
       "      <td>0.377719</td>\n",
       "      <td>0.853053</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.159963</td>\n",
       "      <td>0.442171</td>\n",
       "      <td>0.818105</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.140981</td>\n",
       "      <td>0.375517</td>\n",
       "      <td>0.860211</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.132472</td>\n",
       "      <td>0.459253</td>\n",
       "      <td>0.840421</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.109624</td>\n",
       "      <td>0.434629</td>\n",
       "      <td>0.844211</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092997</td>\n",
       "      <td>0.397693</td>\n",
       "      <td>0.854737</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.082939</td>\n",
       "      <td>0.409582</td>\n",
       "      <td>0.842526</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062485</td>\n",
       "      <td>0.460593</td>\n",
       "      <td>0.833263</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.058828</td>\n",
       "      <td>0.424440</td>\n",
       "      <td>0.837474</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.048399</td>\n",
       "      <td>0.430329</td>\n",
       "      <td>0.846737</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.383456</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.056068</td>\n",
       "      <td>0.432849</td>\n",
       "      <td>0.846737</td>\n",
       "      <td>00:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = get_model_learner()\n",
    "learn.fit_one_cycle(15, slice(1e-5,1e-3))#slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
